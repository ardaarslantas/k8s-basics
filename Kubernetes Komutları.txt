Kubernetes KomutlarÄ± Kubernetes 101

minikube start --driver=docker : bu komut ile docker'da kubernetes komutu baÅŸlatÄ±yorum.

ğŸ”¹ kubectl get nodes : KÃ¼meyi oluÅŸturan fiziksel veya sanal makineleri (node'larÄ±) gÃ¶sterir.

Ã–rnek Ã‡Ä±ktÄ±: 
NAME        STATUS   ROLES           AGE     VERSION
minikube    Ready    control-plane   3d      v1.30.1

ğŸ”¹ kubectl get pods : Kubernetes iÃ§inde Ã§alÄ±ÅŸan uygulamalarÄ±/container'larÄ± kapsayan birimleri (pod'larÄ±) gÃ¶sterir.

Ã–rnek Ã‡Ä±ktÄ±:
NAME                    READY   STATUS    RESTARTS   AGE
nginx-deployment-1     1/1     Running   0          10m

kubectl get nodes -o wide && kubectl get pods -o wide : Daha fazla teknik detay gÃ¶sterir. (-o wide)


ğŸ”¹ kubectl run mypod --image=nginx : image nginx pod oluÅŸturur.

ğŸ”¹ kubectl logs firstpod : podun loglarÄ±nÄ± gÃ¶rÃ¼ntÃ¼ler

ğŸ”¹ kubectl exec -it firstpod -- /bin/sh : podun iÃ§ine girmek iÃ§in kullanÄ±lÄ±r.

ğŸ”¹ kubectl delete pods firstpod : podu silmek iÃ§in kullanÄ±lÄ±r.

ğŸ”¹ kubectl describe pod firstpod : Bir Kubernetes kaynaÄŸÄ±nÄ±n (Ã¶rneÄŸin pod, deployment, service...) ayrÄ±ntÄ±larÄ±nÄ± ve olaylarÄ±nÄ± (Events) gÃ¶sterir.

ğŸ”¹ kubectl apply -f pod1.yaml : pod1.yaml dosyasÄ±ndaki Kubernetes tanÄ±mÄ±nÄ± kÃ¼meye uygular (varsa gÃ¼nceller, yoksa oluÅŸturur). (Pod ise ayaÄŸa kaldÄ±rÄ±r)

ğŸ”¹Init Container: Podâ€™daki ana containerâ€™lardan Ã¶nce Ã§alÄ±ÅŸan, hazÄ±rlÄ±k/baÄŸÄ±mlÄ±lÄ±k kontrolÃ¼ yapan ve iÅŸi bitince kapanan containerâ€™dÄ±r.
ğŸ”¹Init containerâ€™lar genelde Pod veya Deployment YAMLâ€™Ä±nda spec.initContainers: altÄ±nda tanÄ±mlanÄ±r.

ğŸ”¹Label â†’ Pod, Service, Deployment gibi objelere eklenen anahtar/deÄŸer Ã§iftleridir (Ã¶rn: app=nginx). Nesneleri gruplamak ve tanÄ±mlamak iÃ§in kullanÄ±lÄ±r.
ğŸ”¹Selector â†’ Labelâ€™lara gÃ¶re filtreleme yapar. Ã–rn: Service bir Podâ€™u seÃ§erken selector: app=nginx yazarÄ±z â†’ sadece bu labelâ€™a sahip Podâ€™lara trafik gider.

ğŸš€ Label'da iki Ã§eÅŸit filtreleme Ã¶zelliÄŸi bulunmaktadÄ±r. ğŸš€
ğŸ”¹Equality-based â†’ =, ==, != ile tek deÄŸer eÅŸitliÄŸi kontrolÃ¼.
Ã–rn: app=nginx, env!=prod

ğŸ”¹Set-based â†’ in, notin, exists ile Ã§oklu deÄŸer veya varlÄ±k kontrolÃ¼.
Ã–rn: env in (dev,test), tier notin (frontend), app
ğŸ”¹Equality = basit eÅŸitlik, Set-based = liste/varlÄ±k kontrolÃ¼.

ğŸ”¹Label â†’ Objeleri gruplamak ve filtrelemek iÃ§in kullanÄ±lÄ±r. (Ã¶rn: Service, Deployment pod seÃ§erken)
ğŸ”¹Annotation â†’ Objeye ekstra aÃ§Ä±klama/metaveri eklemek iÃ§in kullanÄ±lÄ±r, filtreleme yapÄ±lmaz.


ğŸ”¹Deployment, Podâ€™larÄ± ve onlarÄ±n ReplicaSetâ€™lerini yÃ¶netmek iÃ§in kullanÄ±lÄ±r. AyrÄ± ayrÄ± YAML yazmaya gerek kalmadan tek bir YAML iÃ§inde Pod tanÄ±mÄ±, replicas sayÄ±sÄ± ve yÃ¶netim kurallarÄ± birlikte tanÄ±mlanabilir.
ğŸ”¹Yani: Deployment = Pod + ReplicaSet + YÃ¶netim Ã¶zellikleri (scale, update, rollback).

ğŸš€ Kubernetesâ€™te Deployment iÃ§in strategy.type alanÄ±nda 2 seÃ§enek vardÄ±r: ğŸš€

ğŸ”¹ 1. Recreate
Eski Podâ€™larÄ± tamamen siler, sonra yeni Podâ€™larÄ± baÅŸlatÄ±r.
Dezavantaj â†’ kesinti (downtime) yaÅŸanÄ±r.

ğŸ”¹ 2. RollingUpdate (varsayÄ±lan)
Yeni Podâ€™larÄ± yavaÅŸ yavaÅŸ aÃ§ar, eski Podâ€™larÄ± sÄ±rayla kapatÄ±r.
Kesintisiz gÃ¼ncelleme saÄŸlar.
En Ã§ok kullanÄ±lan strateji budur.
AyrÄ±ca maxUnavailable ve maxSurge gibi ayarlarla Ã¶zelleÅŸtirilebilir.


ğŸš€ maxUnavailable: GÃ¼ncelleme sÄ±rasÄ±nda en fazla 1 Pod devre dÄ±ÅŸÄ± olabilir. ğŸš€
ğŸš€ maxSurge: AynÄ± anda fazladan en fazla 1 yeni Pod aÃ§Ä±labilir. ğŸš€

ğŸ”¹ EÄŸer kind: ReplicaSet iseâ€¦
Kubernetes sadece Pod sayÄ±sÄ±nÄ± sabit tutar.
Versiyonlama, rollout, rollback, update stratejisi gibi ÅŸeyler yoktur.
ReplicaSetâ€™in iÅŸi ÅŸudur: ğŸ‘‰ â€œBenim gÃ¶revim Pod sayÄ±sÄ±nÄ± saymak. EÄŸer eksik varsa aÃ§arÄ±m, fazla varsa silerim.â€

ğŸ”¹ EÄŸer kind: Deployment iseâ€¦
ğŸ”¹Kubernetes arka planda bir ReplicaSet oluÅŸturur.
ğŸ”¹Senin iÃ§in Pod sayÄ±sÄ±nÄ± yine ReplicaSet yÃ¶netir ama ekstra:
ğŸ”¹Rolling update stratejisi,
ğŸ”¹Recreate stratejisi,
ğŸ”¹kubectl rollout undo, kubectl rollout status gibi komutlar,
ğŸ”¹Versiyon geÃ§miÅŸi (revision) saklama.

ğŸ”¹Recreate stratejisi
Ne yapar? Ã–nce tÃ¼m eski Podâ€™larÄ± siler, sonra yenilerini aÃ§ar â†’ downtime olabilir.
ğŸ”¹Ne zaman tercih edilir?
State/lock Ã§akÄ±ÅŸmasÄ± riskinde (aynÄ± veritabanÄ±na aynÄ± anda iki sÃ¼rÃ¼m baÄŸlanmasÄ±n).
Eski ve yeni sÃ¼rÃ¼mÃ¼n aynÄ± anda Ã§alÄ±ÅŸmasÄ± kesinlikle istenmiyorsa.

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ Kubectl Rollout KomutlarÄ± (Deployment iÃ§in)

ğŸ”¹ kubectl rollout status
AmaÃ§: GÃ¼ncellemenin ilerleyiÅŸini ve sonucunu gÃ¶sterir.
KullanÄ±m:
kubectl rollout status deployment/my-app

Ã‡Ä±ktÄ±lar:
successfully rolled out â†’ GÃ¼ncelleme tamam.
Beklemede kalÄ±rsa â†’ Podâ€™lar Ready olmamÄ±ÅŸtÄ±r (health check/probe kontrol et).

ğŸ”¹ kubectl rollout undo
AmaÃ§: Son gÃ¼ncellemeyi geri alÄ±r (bir Ã¶nceki revisionâ€™a dÃ¶ner).
KullanÄ±m:
kubectl rollout undo deployment/my-app

Belirli bir revisionâ€™a dÃ¶nmek iÃ§in:
kubectl rollout undo deployment/my-app --to-revision=3

ğŸ”¹ kubectl rollout history
AmaÃ§: Deploymentâ€™Ä±n versiyon (revision) geÃ§miÅŸini gÃ¶sterir.
KullanÄ±m:
kubectl rollout history deployment/my-app

Belirli bir revision detayÄ±nÄ± gÃ¶rmek:
kubectl rollout history deployment/my-app --revision=2


ğŸ”¹Change Cause (aÃ§Ä±klama):
Eskiden --record flagâ€™i ile otomatik kaydediliyordu (deprecated).
ArtÄ±k manuel annotation ekleniyor:
kubectl annotate deployment my-app kubernetes.io/change-cause="nginx sÃ¼rÃ¼mÃ¼ 1.27.1'e gÃ¼ncellendi"

ğŸ”¹ YardÄ±mcÄ± Komutlar
Duraklat / Devam ettir:
kubectl rollout pause deployment/my-app
kubectl rollout resume deployment/my-app
BÃ¼yÃ¼k gÃ¼ncellemeleri parÃ§a parÃ§a kontrol etmek iÃ§in faydalÄ±.

ğŸ”¹ Yeni image set ederek gÃ¼ncelleme tetiklemek:
kubectl set image deployment/my-app nginx=nginx:1.27.1
Buradaki nginx â†’ Pod template iÃ§indeki container adÄ±.


ğŸ”¹ Kubernetes Network Temelleri

ğŸ”¹Pod-to-Pod Communication
Clusterâ€™daki her podâ€™un kendi IP adresi var.
Flat Network mantÄ±ÄŸÄ±: TÃ¼m podâ€™lar birbirine NAT olmadan eriÅŸebilmeli.
Bu iÅŸi CNI (Container Network Interface) pluginleri yapar (Calico, Flannel, Cilium vs.).

ğŸ”¹Service
Pod IPâ€™leri dinamik olduÄŸundan (pod Ã¶lÃ¼r/yeni pod yaratÄ±lÄ±r), stabil bir eriÅŸim noktasÄ± lazÄ±m.
Service bu noktayÄ± saÄŸlar â†’ DNS Ã¼zerinden sabit isimle ulaÅŸabilirsin (my-app.default.svc.cluster.local).

ğŸ”¹Ingress
Service genellikle cluster iÃ§i eriÅŸim saÄŸlar.
DÄ±ÅŸ dÃ¼nyadan eriÅŸim iÃ§in Ingress kullanÄ±lÄ±r (Ã¶r: Nginx Ingress Controller).
Domain bazlÄ± routing, TLS termination gibi Ã¶zellikler verir.

ğŸ”¹API Server ile Ä°letiÅŸim
kubectl senin bilgisayarÄ±ndan API Serverâ€™a HTTP(S) request atar.
kubelet ise node Ã¼zerinde Ã§alÄ±ÅŸÄ±p API Serverâ€™a sÃ¼rekli status raporlar ve pod specâ€™lerini alÄ±r.

ğŸ”¹Service ile ilgili eÄŸitim dÃ¶kÃ¼manÄ±ndaki service klasÃ¶rÃ¼ iÃ§erisindeki yaml dosyalarÄ± kontrol edilmedilir...ğŸ”¹

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ Liveness Probe Nedir?
AmaÃ§: Bir Pod iÃ§indeki containerâ€™Ä±n hala Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol eder.
EÄŸer probe baÅŸarÄ±sÄ±z olursa Kubernetes containerâ€™Ä± Ã¶ldÃ¼rÃ¼r (kill eder) ve yeniden baÅŸlatÄ±r.
Yani uygulaman Ã§alÄ±ÅŸÄ±yor gÃ¶rÃ¼nÃ¼p aslÄ±nda takÄ±lÄ±p kalmÄ±ÅŸ olabilir â†’ iÅŸte bu durumda livenessProbe onu otomatik olarak resetler.

ğŸ“Œ KullanÄ±m Senaryosu
Uygulama processâ€™i â€œrunâ€ durumunda gÃ¶rÃ¼nÃ¼yor ama aslÄ±nda cevap vermiyor (Ã¶rn: deadlock, sonsuz dÃ¶ngÃ¼, RAM tÃ¼kendi).
Restart edilirse sorun dÃ¼zeliyor.
livenessProbe sayesinde bu otomatik yapÄ±lÄ±r, manuel mÃ¼dahale gerekmez.

ğŸ“Œ Ã–nemli Parametreler
initialDelaySeconds â†’ Ä°lk kontrol yapÄ±lmadan Ã¶nce beklenecek sÃ¼re. (uygulama aÃ§Ä±lÄ±ÅŸta zaman istiyorsa Ã¶nemli)
periodSeconds â†’ KaÃ§ saniyede bir kontrol yapÄ±lacak.
timeoutSeconds â†’ KontrolÃ¼n zaman aÅŸÄ±mÄ±.
failureThreshold â†’ KaÃ§ defa arka arkaya hata alÄ±nca baÅŸarÄ±sÄ±z sayÄ±lacak.
successThreshold â†’ KaÃ§ defa baÅŸarÄ±lÄ± olunca tekrar saÄŸlÄ±klÄ± kabul edilecek (genelde readiness iÃ§in kullanÄ±lÄ±r).

ğŸ“Œ Readiness Probe Nedir?
AmaÃ§: Bir Pod iÃ§indeki containerâ€™Ä±n trafiÄŸe hazÄ±r olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
EÄŸer probe baÅŸarÄ±sÄ±z olursa Kubernetes containerâ€™Ä± Ã¶ldÃ¼rmez, sadece Service trafiÄŸini bu Podâ€™a yÃ¶nlendirmez.
Yani uygulama â€œyaÅŸÄ±yorâ€ olabilir ama hazÄ±r deÄŸilse (Ã¶rn: DBâ€™ye baÄŸlanmadÄ±, cache yÃ¼klenmedi) â†’ readinessProbe sayesinde o Podâ€™a istek gitmez.

ğŸ“Œ KullanÄ±m Senaryosu
Uygulama yeni aÃ§Ä±lÄ±yor ama henÃ¼z baÄŸlantÄ±larÄ± kurmadÄ±.
Uygulama Ã§alÄ±ÅŸÄ±yor ama geÃ§ici olarak servis veremiyor (Ã¶rn: bakÄ±m modu, backend yanÄ±t vermiyor).
Rolling update sÄ±rasÄ±nda yeni Pod hazÄ±r olana kadar trafik almasÄ±n istiyoruz.

ğŸ“Œ Ã–nemli Parametreler
initialDelaySeconds â†’ Ä°lk kontrol yapÄ±lmadan Ã¶nce beklenecek sÃ¼re. (Ã¶rn: aÃ§Ä±lÄ±ÅŸta appâ€™in hazÄ±r olmasÄ± uzun sÃ¼rÃ¼yorsa)
periodSeconds â†’ KaÃ§ saniyede bir kontrol yapÄ±lacak.
timeoutSeconds â†’ KontrolÃ¼n zaman aÅŸÄ±mÄ± sÃ¼resi.
failureThreshold â†’ KaÃ§ defa arka arkaya hata alÄ±nca Pod â€œNotReadyâ€ sayÄ±lacak.
successThreshold â†’ KaÃ§ defa arka arkaya baÅŸarÄ±lÄ± olunca Pod tekrar â€œReadyâ€ kabul edilecek. (Readiness iÃ§in Ã§ok Ã¶nemlidir ğŸ‘)

âœ… KÄ±saca Fark:
Liveness = Container yaÅŸÄ±yor mu? (Fail â†’ Restart)
Readiness = Container hazÄ±r mÄ±? (Fail â†’ TrafiÄŸe kapat, ama restart etme)

ğŸš€ readinessProbe ve livenessProbe yaml dosyalarÄ± kontrol edilmelidir. ğŸš€

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ Kubernetes Resource Requests & Limits â€“ Ã–zet Not

requests
Podâ€™un garanti edilen minimum kaynak ihtiyacÄ±.
Scheduler Podâ€™u bir nodeâ€™a yerleÅŸtirirken bu deÄŸeri dikkate alÄ±r.

Ã–rn: memory: "64M" â†’ bu Pod iÃ§in en az 64 MB RAM ayÄ±r.
Ã–rn: cpu: "250m" â†’ en az 0.25 CPU ayÄ±r.

limits
Podâ€™un kullanabileceÄŸi maksimum kaynak.
RAM aÅŸÄ±lÄ±rsa â†’ Container OOMKilled (Ã¶lÃ¼r, yeniden baÅŸlar).
CPU aÅŸÄ±lÄ±rsa â†’ Container throttle edilir (yavaÅŸlatÄ±lÄ±r, down olmaz).

Ã–rn: memory: "256M" â†’ Pod max 256 MB RAM kullanabilir.
Ã–rn: cpu: "0.5" â†’ Pod max yarÄ±m CPU kullanabilir.

âœ… Kural:
RAM aÅŸÄ±lÄ±rsa â†’ Pod down olur (OOMKilled â†’ restart).
CPU aÅŸÄ±lÄ±rsa â†’ Pod Ã§alÄ±ÅŸmaya devam eder ama yavaÅŸlar.

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ Environment Variables (env)
ğŸ”¹ Container iÃ§ine dÄ±ÅŸarÄ±dan deÄŸiÅŸken tanÄ±mlamak iÃ§in kullanÄ±lÄ±r.
ğŸ”¹ Uygulama ayarlarÄ±nÄ± YAML Ã¼zerinden vermeyi saÄŸlar.
ğŸ”¹ env: altÄ±nda name ve value ile tanÄ±mlanÄ±r.

Ã–rnek:
env:
  - name: APP_MODE
    value: "production"

ğŸ”¹ Container iÃ§inde echo $APP_MODE veya printenv ile gÃ¶rÃ¼lebilir.
ğŸ”¹ ConfigMap ve Secret ile birlikte daha sonra dinamik hale getirilebilir.

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ Secret (Gizli Veri) Nedir?

ğŸ”¹ Kubernetesâ€™te hassas bilgileri (ÅŸifre, API key, token, vs.) gÃ¼venli ÅŸekilde saklamak iÃ§in kullanÄ±lÄ±r.
ğŸ”¹ ConfigMapâ€™e benzer ama veriler base64 ile encode edilerek tutulur.
ğŸ”¹ Secret iÃ§indeki veriler Podâ€™a env (environment) olarak veya dosya (volume) olarak aktarÄ±labilir.
ğŸ”¹ AmaÃ§, gizli bilgileri YAML dosyalarÄ±na veya image iÃ§ine yazmadan dÄ±ÅŸarÄ±dan vermektir.

ğŸ”¹ OluÅŸturma Ã–rneÄŸi:

kubectl create secret generic mysecret3 \
  --from-file=db_server=server.txt \
  --from-file=db_username=username.txt \
  --from-file=db_password=password.txt


â¡ï¸ Bu komut mysecret3 adÄ±nda bir Secret oluÅŸturur,
ve her dosyanÄ±n iÃ§eriÄŸini key/value olarak saklar.

ğŸ”¹ GÃ¶rÃ¼ntÃ¼leme:

kubectl get secrets
kubectl describe secret mysecret3
kubectl get secret mysecret3 -o yaml


ğŸ”¹ Pod iÃ§inde kullanma yollarÄ±:
1ï¸âƒ£ Env olarak:
Secret deÄŸerlerini environment deÄŸiÅŸkeni gibi alÄ±r.

env:
  - name: username
    valueFrom:
      secretKeyRef:
        name: mysecret3
        key: db_username


2ï¸âƒ£ Volume olarak:
Secret deÄŸerlerini dosya ÅŸeklinde container iÃ§ine yazar.

volumeMounts:
  - name: secret-vol
    mountPath: /secret
volumes:
  - name: secret-vol
    secret:
      secretName: mysecret3


ğŸ”¹ GÃ¼venlik Notu:
Secrets, base64 ile encode edilir ama ÅŸifrelenmez â€”
bu yÃ¼zden Ã¼retim ortamlarÄ±nda encryption at rest (diskte ÅŸifreleme) Ã¶zelliÄŸi aktif edilmelidir.

ğŸ”¹ KÄ±saca:
ConfigMap â†’ yapÄ±landÄ±rma bilgileri
Secret â†’ hassas bilgileri gÃ¼venli ÅŸekilde saklamak iÃ§in

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ NodeAffinity
Podâ€™un hangi nodeâ€™da veya hangi podlarÄ±n yanÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lan kurallar bÃ¼tÃ¼nÃ¼dÃ¼r.

ğŸ”¹ Node labelâ€™a bakar
ğŸ”¹ required = uymazsa pending
ğŸ”¹ preferred = uymazsa Ã§alÄ±ÅŸÄ±r
ğŸ”¹ Node seÃ§imi iÃ§in
ğŸ”¹ GPU/SSD/RAM/zone gibi durumlarda

ğŸ“Œ PodAffinity

ğŸ”¹ Pod labelâ€™a bakar
ğŸ”¹ Podâ€™u diÄŸer podlarÄ±n yanÄ±na koyar
ğŸ”¹ YakÄ±n yerleÅŸim (same node/zone)
ğŸ”¹ required = zorunlu
ğŸ”¹ preferred = mÃ¼mkÃ¼nse
ğŸ”¹ frontend+cache gibi senaryolarda

ğŸ“Œ PodAntiAffinity

ğŸ”¹ Pod labelâ€™a bakar
ğŸ”¹ PodlarÄ± birbirinden uzak tutar
ğŸ”¹ Replicaâ€™larÄ± farklÄ± nodeâ€™lara daÄŸÄ±tÄ±r
ğŸ”¹ YÃ¼ksek eriÅŸilebilirlik (HA) saÄŸlar
ğŸ”¹ required/preferred destekler

ğŸ“Œ Fark KÄ±saca

ğŸ”¹ NodeAffinity = node seÃ§imi
ğŸ”¹ PodAffinity = pod komÅŸuluÄŸu
ğŸ”¹ PodAntiAffinity = pod daÄŸÄ±lÄ±mÄ±

ğŸ“Œ topologyKey

ğŸ”¹ hostname â†’ aynÄ± node
ğŸ”¹ zone â†’ aynÄ± zone
ğŸ”¹ region â†’ aynÄ± bÃ¶lge

ğŸ“Œ OperatÃ¶rler

ğŸ”¹ In â†’ listedekilerden biri
ğŸ”¹ NotIn â†’ listedekilerden biri deÄŸil
ğŸ”¹ Exists â†’ key varsa yeter
ğŸ”¹ DoesNotExist â†’ key yoksa eÅŸleÅŸir

ğŸ“Œ KÄ±sacasÄ±
NodeAffinity â†’ hangi nodeâ€™a gitsin?
PodAffinity â†’ hangi podun yanÄ±na gitsin?
PodAntiAffinity â†’ hangi podlardan uzak dursun?


ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ Taint Nedir?

Nodeâ€™a konulan bir kuraldÄ±r.
MantÄ±k: â€œBenim Ã¼zerime her pod gelemez, sadece izin verdiÄŸim podlar gelebilir.â€

Nodeâ€™u iten/uzaklaÅŸtÄ±ran bir etiket gibidir.

ÃœÃ§ parÃ§adan oluÅŸur:
key=value:Effect

ğŸ¯ Taint Effect TÃ¼rleri â€“ SÃ¼per Basit AÃ§Ä±klama
1ï¸âƒ£ NoSchedule
ğŸ‘‰ â€œYeni podlarÄ± buraya getirme.â€
  YENÄ° podlar bu nodeâ€™a gelemez
  Ama nodeâ€™da zaten Ã§alÄ±ÅŸan podlar kalÄ±r
KÄ±sacasÄ±:
âŒ Yeni pod yok
âœ”ï¸ Eski podlar durabilir

2ï¸âƒ£ PreferNoSchedule
ğŸ‘‰ â€œMÃ¼mkÃ¼nse yeni podlarÄ± buraya getirme; ama Ã§ok gerekirse getirebilirsin.â€
Kubernetes Ã¶nce diÄŸer node'lara gÃ¶ndermeye Ã§alÄ±ÅŸÄ±r
Ama baÅŸka yer yoksa yine de bu nodeâ€™a koyabilir

KÄ±sacasÄ±:
â¡ï¸ Yasak deÄŸil, sadece tavsiye.
Kubernetes: â€œBuraya koymasam iyi olur ama zorunluysa koyarÄ±m.â€

3ï¸âƒ£ NoExecute
ğŸ‘‰ â€œYeni podlarÄ± alma, var olanlarÄ± da kov.â€
Yeni podlar gelemez
Zaten Ã§alÄ±ÅŸan podlar da atÄ±lÄ±r / taÅŸÄ±nÄ±r
KÄ±sacasÄ±:
âŒ Yeni pod yok
âŒ Eski podlar da kalamaz â†’ dÄ±ÅŸarÄ± atÄ±lÄ±r

Ã–rnek
kubectl taint nodes node1 role=db:NoSchedule


Bu nodeâ€™a sadece tolerationâ€™Ä± olan podlar gelebilir.

ğŸ“Œ Toleration Nedir?

Podâ€™un Ã¼zerinde olur.
MantÄ±k: â€œBu pod, belirtilen tainti tolere edebilir, yani o nodeâ€™da Ã§alÄ±ÅŸabilir.â€

Taintâ€™ten korkmayan pod demektir.

Podâ€™un spec kÄ±smÄ±na eklenir.

Ã–rnek
tolerations:
  - key: "role"
    operator: "Equal"
    value: "db"
    effect: "NoSchedule"


Bu pod, role=db:NoSchedule taint'i olan nodeâ€™a gitmeye izinli olur.

ğŸ« Toleration ne saÄŸlÄ±yor?

Toleration â†’ â€œBu taintâ€™i tolere ediyorum, o nodeâ€™a gelebilirim.â€ geÃ§iÅŸ izni.

Bu yÃ¼zden:

âœ”ï¸ Yeni pod + toleration varsa â†’ node kabul eder
âœ”ï¸ Eski pod + toleration varsa â†’ zaten kabul edilir veya kalabilir
âŒ Yeni pod + toleration yok â†’ NO SCHEDULE â†’ reddedilir
âœ”ï¸ Eski pod + toleration yok â†’ nodeâ€™dan ATILMAZ

ğŸ§  KÄ±sa Ã–zet 

Taint = Nodeâ€™a â€œbenden uzak durunâ€ bariyeri koymak.

Toleration = Podâ€™un â€œben o bariyeri geÃ§ebilirimâ€ demesi.

Taint nodeâ€™da olur â†’ sÄ±nÄ±rlama.

Toleration podâ€™da olur â†’ izin.



ğŸ¯ Nerede KullanÄ±lÄ±r?

Sadece belirli podâ€™larÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in Ã¶zel nodeâ€™lar varsa
(Ã¶r. database node, gpu node, monitoring node)

Sistemde istenmeyen podâ€™larÄ±n yanlÄ±ÅŸ nodda Ã§alÄ±ÅŸmasÄ±nÄ± engellemek iÃ§in.

Eviction / NoExecute ile pod atma senaryolarÄ±nda.

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ DaemonSet Nedir?

Bir DaemonSet, Kubernetesâ€™te her node Ã¼zerinde bir pod Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lan kontrol yapÄ±sÄ±dÄ±r.

ğŸ§² MantÄ±k:
Clusterâ€™da 5 node varsa â†’ DaemonSet 5 pod oluÅŸturur.
Yeni node eklersen â†’ otomatik o nodeâ€™da da bir pod aÃ§Ä±lÄ±r.
Node silinir â†’ DaemonSet podâ€™u da silinir.

ğŸ“Œ DaemonSet Ne Ä°ÅŸe Yarar?

Her nodeâ€™da arka plan ajanlarÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r.

Ã–rnek kullanÄ±m alanlarÄ±:

ğŸ“„ Log toplama (Fluentd, Filebeat)

ğŸ“ˆ Node metrics Agent (Node Exporter, Metricbeat)

ğŸ” Monitoring agent (Prometheus Node Exporter)

ğŸ” Security agent (Falco)

ğŸ“¡ Network pluginler (Calico, Cilium)

ğŸ³ Storage pluginler

ğŸ“Œ DaemonSet Podâ€™larÄ± NasÄ±l Ã‡alÄ±ÅŸÄ±r?

Scheduler her nodeâ€™a 1 pod dÃ¼ÅŸÃ¼rÃ¼r.

Pod sayÄ±sÄ± node sayÄ±sÄ± kadar olur.

Node=3 â†’ Pod=3

Node=5 â†’ Pod=5

Yani replica deÄŸeri yoktur.
Scale-out = yeni node ekle.
Scale-in = node sil.

ğŸ“Œ DaemonSetâ€™in Ã–zellikleri
âœ” Her nodeâ€™da ayni podâ€™u Ã§alÄ±ÅŸtÄ±rÄ±r

Kopya sayÄ±sÄ± node countâ€™tur.

âœ” Node eklendiÄŸinde otomatik pod ekler

El ile scale etmezsin.

âœ” nodeSelector / tolerations kullanÄ±labilir

Hangi nodeâ€™larda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± seÃ§ebilirsin.

ğŸ”¹ Ã–rnek: sadece worker nodeâ€™larÄ±nda
ğŸ”¹ Ã–rnek: master nodeâ€™larda da Ã§alÄ±ÅŸsÄ±n (toleration ekleyerek)

ğŸ“Œ DaemonSet ile Deployment farkÄ±
Ã–zellik	Deployment	DaemonSet
Pod sayÄ±sÄ±	Sen belirlersin (replicas)	Her nodeâ€™da 1
Scale	Komutla scale edilir	Node sayÄ±sÄ±na gÃ¶re
KullanÄ±m alanÄ±	Web app, API	Ajan, log collector
Node baÄŸÄ±msÄ±zlÄ±ÄŸÄ±	Evet	HayÄ±r, node baÄŸlÄ±

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ“Œ PV ve PVC Nedir? (Kubernetes Depolama Temelleri)
ğŸ§± 1. PersistentVolume (PV) â€” KalÄ±cÄ± Depolama AlanÄ±

PV, Kubernetes cluster iÃ§inde hazÄ±r bekleyen fiziksel depolama alanÄ±dÄ±r.

Admin tarafÄ±ndan oluÅŸturulur

KÃ¼me genelinde ortak kaynaktÄ±r

Podâ€™dan baÄŸÄ±msÄ±zdÄ±r (Pod silinse bile veriler silinmez)

NFS, HostPath, Ceph, Cloud disk (EBS, AzureDisk) olabilir

PV = GerÃ§ek depolama diski


ğŸ“ 2. PersistentVolumeClaim (PVC) â€” Podâ€™un Depo Talebi

PVC, uygulamanÄ±n disk istemesidir.

Pod â€œbana 5Gi disk lazÄ±mâ€ der â†’ PVC oluÅŸturur

Kubernetes uygun bir PV bulur â†’ eÅŸleÅŸtirir (binding)

PVC â†’ PVâ€™ye baÄŸlanÄ±nca pod diski kullanabilir

PVC = UygulamanÄ±n disk talebi


ğŸ”— 3. PV â€“ PVC EÅŸleÅŸmesi NasÄ±l Ã‡alÄ±ÅŸÄ±r?

PVC ÅŸunu der:

"AccessMode: ReadWriteOnce, Size: 5Gi olan bir PV istiyorum."

PVâ€™ler incelenir â†’ Uygun olan bulunursa â†’ Otomatik bind edilir.

EÅŸleÅŸme olduÄŸunda:

PV Bound olur

PVC Bound olur

Pod iÃ§indeki container diski mount eder


ğŸ“‚ 4. AccessModes (Ã–nemli!)
Mode	AÃ§Ä±klama
ReadWriteOnce (RWO)	Sadece 1 node tarafÄ±ndan okunup yazÄ±labilir
ReadOnlyMany (ROX)	Birden fazla node okuyabilir
ReadWriteMany (RWX)	Birden fazla node okuyup yazabilir (NFS, GlusterFS vs.)


ğŸ­ 5. StorageClass â€” Dinamik PV FabrikasÄ±

StorageClass, PVC oluÅŸturulduÄŸunda otomatik PV Ã¼reten bir sÄ±nÄ±ftÄ±r.

â€œDisk Ã¼retim ÅŸablonudur.â€

Cloud ortamÄ±nda EBS / AzureDisk / GCEPersistentDisk gibi kaynaklarÄ± yaratÄ±r

Local PV kullanÄ±mÄ±nda node-affinity uyumlu diskleri doÄŸru zoneâ€™da oluÅŸturur

StorageClass olmadan:
â†’ PVâ€™leri elle oluÅŸturursun.

StorageClass ile:
â†’ PVC gelince otomatik PV oluÅŸturulur (Dynamic Provisioning).

ğŸ’¡ StorageClass = Otomatik PV Ã¼reten fabrika.


âš™ï¸ 6. volumeBindingMode TÃ¼rleri

StorageClass iÃ§inde yer alan Ã¶nemli ayar:

6.1 Immediate (VarsayÄ±lan)

PVC oluÅŸturulur â†’ PV hemen oluÅŸturulur
Podâ€™un hangi nodeâ€™da Ã§alÄ±ÅŸacaÄŸÄ± Ã¶nemli deÄŸildir

KullanÄ±m:
Node baÄŸÄ±mlÄ±lÄ±ÄŸÄ± olmayan depolar
(NFS, Ceph, GlusterFS)

Risk:
Cloud ortamÄ±nda yanlÄ±ÅŸ zoneâ€™da PV oluÅŸturabilir
ve Pod asla Ã§alÄ±ÅŸamaz.
volumeBindingMode: Immediate

6.2 WaitForFirstConsumer (Ã–nerilen)

PVC oluÅŸturulur â†’ PV hemen oluÅŸturulmaz
Kubernetes Ã¶nce Podâ€™un node seÃ§im sÃ¼recini bekler
Podâ€™un dÃ¼ÅŸeceÄŸi node belirlendikten sonra
â†’ PV o nodeâ€™un zoneâ€™una uygun ÅŸekilde oluÅŸturulur

Avantaj:
Zone/region uyuÅŸmazlÄ±ÄŸÄ± tamamen Ã§Ã¶zÃ¼lÃ¼r
Local PV iÃ§in ÅŸarttÄ±r
KullanÄ±m:
AWS EBS, AzureDisk, GCE PD, Local storage

volumeBindingMode: WaitForFirstConsumer

ğŸ’¡ En gÃ¼venli ve en modern tercih budur.

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

Job & CronJob Nedir ?

ğŸ§± Job

Ne yapar?
â¡ï¸ Tek seferlik iÅŸ Ã§alÄ±ÅŸtÄ±rÄ±r, bitince durur.

KullanÄ±m:

DB migration

Batch / script

Backup (manuel)

Ã–zet Ã¶zellikler:

BaÅŸarÄ±lÄ± olana kadar retry

Bitince Pod kapanÄ±r

SÃ¼rekli Ã§alÄ±ÅŸmaz

restartPolicy: Never
backoffLimit: 3 â¡ï¸ Pod 3 kez baÅŸarÄ±sÄ±z olursa, Job Failed olur ve durur.

â° CronJob

Ne yapar?
â¡ï¸ Jobâ€™u zamanlanmÄ±ÅŸ ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±r.

KullanÄ±m:

GÃ¼nlÃ¼k backup

Saatlik temizlik

HaftalÄ±k rapor

schedule: "0 2 * * *"   # Her gÃ¼n 02:00


Ã–nemli ayarlar:

concurrencyPolicy: Forbid
successfulJobsHistoryLimit: 3

ğŸ†š Job vs CronJob

Job â†’ Bir kere Ã§alÄ±ÅŸÄ±r

CronJob â†’ ZamanlÄ± Ã§alÄ±ÅŸÄ±r

ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹

ğŸ” RBAC & Service Account (SA)

ğŸ§© RBAC Nedir?
RBAC = Role Based Access Control
â¡ï¸ Kubernetesâ€™te yetki yÃ¶netimi yapmamÄ±zÄ± saÄŸlayan sistemdir.

ğŸ¯ Ne iÃ§in kullanÄ±lÄ±r?

RBAC; bir kimliÄŸin hangi kaynaÄŸa, hangi iÅŸlemi yapabileceÄŸini belirlemek iÃ§in kullanÄ±lÄ±r.

3 temel soru

RBAC ÅŸunu cevaplar:

Kim? â†’ User / ServiceAccount

Nereye? â†’ Hangi resource (pod, secret, deploymentâ€¦)

Ne yapabilir? â†’ get, list, create, deleteâ€¦

ğŸ§± RBAC Neyi Ã‡Ã¶zÃ¼yor?
Problem	RBAC Ã§Ã¶zÃ¼mÃ¼
Herkes her ÅŸeyi gÃ¶rmesin	EriÅŸimi sÄ±nÄ±rlar
Podâ€™lar fazla yetkiyle Ã§alÄ±ÅŸmasÄ±n	Minimum yetki (least privilege)
YanlÄ±ÅŸlÄ±kla silme/bozma riski	Ä°zinleri parÃ§alara ayÄ±rÄ±r
Prod/stg/env ayrÄ±mÄ±	Namespace bazlÄ± yetkilendirme

RBAC = Kontrol + GÃ¼venlik + SÄ±nÄ±rlandÄ±rma

ğŸ” Temel ParÃ§alarÄ±
BileÅŸen	GÃ¶revi	Kapsam
Role	Ä°zinlerin listesi	Namespace
ClusterRole	Ä°zinlerin listesi	TÃ¼m cluster
RoleBinding	RolÃ¼ bir kimliÄŸe verir	Namespace
ClusterRoleBinding	ClusterRoleâ€™Ã¼ kimliÄŸe verir	TÃ¼m cluster

ğŸ“Œ Role izin tanÄ±mlar, Binding o izni birine verir.

ğŸ­ Kimlik TÃ¼rleri

Kimlik (identity) = RBACâ€™Ä±n yetki verdiÄŸi hedef

Kimlik	Ne iÃ§in?
User	Ä°nsan / Admin
ServiceAccount	Pod / uygulama
Group	Toplu kullanÄ±cÄ±lar

Pod bir talep yaparsa â†’ ServiceAccount kimliÄŸi kullanÄ±r.

âš™ï¸ Ä°ÅŸleyiÅŸ MantÄ±ÄŸÄ± (AkÄ±ÅŸ)
Pod / User
   â†“ (kim?)
Token / Cert
   â†“ Authentication (401?)
RBAC â†’ Role/ClusterRole (403?)
   â†“
Resource â†’ Ä°ÅŸlem gerÃ§ekleÅŸir


Token doÄŸru â†’ âœ”ï¸ 401 geÃ§ildi
Yetki doÄŸru â†’ âœ”ï¸ 403 geÃ§ildi

âœ”ï¸ Basit Ã–rnek Senaryolar
Senaryo	Ne yapÄ±lÄ±r?
Podâ€™lar sadece listeleme yapsÄ±n	Role + RoleBinding
Developer sadece logâ€™lara baksÄ±n	Role + Binding (get/list)
CI/CD sadece deploy atsÄ±n	Role (create/update) + Binding
Admin tam yetkili olsun	âš ï¸ ClusterRoleBinding (dikkat!)
ğŸ“Œ Verbs (Ä°ÅŸlemler)

RBAC izinleri verbs ile ifade eder:

get â†’ okunur

list â†’ listelenir

watch â†’ izlenir

create â†’ oluÅŸturulur

update â†’ gÃ¼ncellenir

delete â†’ silinir

Read: get + list + watch

ğŸ¯ Ã–zet CÃ¼mle

RBAC = Kubernetesâ€™te â€œkimin ne yapabileceÄŸiniâ€ belirleyen sistemdir.
KullanÄ±m amacÄ±: Yetki, kontrol, gÃ¼venlik.

ğŸ’ AkÄ±lda KalmasÄ± Ä°Ã§in
Kim?           â†’ User / SA
Ne?            â†’ Resource (pods, secrets...)
NasÄ±l?         â†’ Verbs (get, listâ€¦)
Nerede?        â†’ Namespace / Cluster


ServiceAccount Nedir ?

â¡ï¸ Podâ€™un kimliÄŸidir.
Podâ€™un Kubernetes APIâ€™si ile konuÅŸmasÄ±nÄ± saÄŸlar.
Ä°nsanlarÄ±n kimliÄŸi â†’ User
Podâ€™larÄ±n kimliÄŸi â†’ ServiceAccount

ğŸ“Œ Ne iÃ§in kullanÄ±lÄ±r?

Podâ€™un K8s APIâ€™ye eriÅŸmesi iÃ§in
Podâ€™a RBAC ile yetki vermek iÃ§in
CI/CD, Operator, Controller gibi otomatik iÅŸlemlerde

ğŸ”‘ En Ã¶nemli mantÄ±k
SA = Kimlik
RBAC = Yetki

SA tek baÅŸÄ±na yetki vermez, sadece â€œben buyumâ€ der.
RBAC eklersen â€œÅŸunu yapabilirsinâ€ olur.

ğŸ§± Ã‡alÄ±ÅŸma akÄ±ÅŸÄ±
Pod â†’ ServiceAccount â†’ Token â†’ API Server â†’ RBAC kontrolÃ¼

Token doÄŸru deÄŸilse â†’ 401
Yetki yoksa â†’ 403

ğŸ“ Nerede bulunur?

Her namespaceâ€™te otomatik default SA vardÄ±r.
Belirtmezsen Pod bunu kullanÄ±r.

Pod iÃ§indeki token yolu:

/var/run/secrets/kubernetes.io/serviceaccount/token